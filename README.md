# CycleGAN: Перенос стиля Клода Моне

## Описание задачи

В данном проекте показана реализация CycleGAN для переноса художественного стиля на фотографии. Проект выполнен в рамках Kaggle соревнования "I'm Something of a Painter Myself": https://www.kaggle.com/competitions/gan-getting-started/overview.

Цель - преобразовать обычные фотографии в картины в стиле Клода Моне.

В соревновании Kaggle "I'm Something of a Painter Myself" моя реализация CycleGAN входит в **топ 15%**  решений. 

## Архитектура

CycleGAN использует две пары моделей:

**Два генератора:**
- `G_photo_to_monet` - преобразует фотографии в картины стиля Моне
- `G_monet_to_photo` - выполняет обратное преобразование

**Два дискриминатора:**
- `D_photo` - различает реальные и сгенерированные фотографии
- `D_monet` - различает реальные картины Моне и сгенерированные

## Датасет

Для обучения использовались данные из Kaggle соревнования, состоящие из двух независимых частей:

- Картины Моне:
300 оцифрованных картин Клода Моне.


<img width="292" height="291" alt="image" src="https://github.com/user-attachments/assets/b3bffa5f-0f65-433f-8b78-62c4f1360ef0" /> <img width="291" height="290" alt="image" src="https://github.com/user-attachments/assets/730cd67e-c7d8-4bcd-965c-d6aabed208c3" /> <img width="290" height="291" alt="image" src="https://github.com/user-attachments/assets/1a14caf7-376d-4d37-9122-9d385ffaecaa" />


- Фотографии:
7028 современных различных фотографий.


<img width="291" height="290" alt="image" src="https://github.com/user-attachments/assets/e40aeca3-2ed7-4745-8d8f-681710321de1" /> <img width="291" height="291" alt="image" src="https://github.com/user-attachments/assets/02fd76dd-cb1c-47fb-b69c-866e1369707e" /> <img width="291" height="291" alt="image" src="https://github.com/user-attachments/assets/adddbd2c-01ed-41be-910f-5d97723ee63e" />


Для оптимизации времени обучения (из-за ограничений в соревновании) было случайным образом отобрано 1000 изображений.

*Ключевая особенность датасета - непарность*.
В отличие от классических задач image-to-image, здесь отсутствуют парные данные. Это означает, что нет конкретных пар "фотография - соответствующая ей картина Моне". Это сложнее, так как в парных данных модель просто учится отображению (фото собаки - картина этой же собаки в стиле Моне), а в непарных данных модель должна понять абстрактное понятие "стиль Моне" и применить его к любой фотографии.
Решение данной проблемы заключается в использовании cycle consistency loss - функция потерь, которая обеспечивает циклическую согласованность - преобразованное изображение можно обратно восстановить в исходное, сохранив структуру и ключевые элементы. Это заменяет необходимость в парных данных и позволяет модели учиться переносу стиля без явного соответствия между изображениями.

## Функция потерь

Общая функция потерь генератора состоит из трех компонентов:

1. **Adversarial Loss** (MSELoss)
   - Измеряет способность генератора создавать реалистичные данные, способные обмануть дискриминатор

2. **Cycle Consistency Loss** (L1Loss, λ=10.0)
   - Измеряет разницу между восстановленным изображением и входным изображением, т.е. гарантирует обратимость преобразования

3. **Identity Loss** (L1Loss, λ=0.5)
   - Измеряет степень сходства между исходным изображением и результатом генерации, стремясь к тому, чтобы сгенерированное изображение было неотличимо от оригинала

**Итоговая формула:**
Total_Loss = Adversarial_Loss + 10.0 * Cycle_Loss + 5.0 * Identity_Loss,
где Identity_Loss умножается на λ_cycle * λ_identity = 10.0 * 0.5 = 5.0

## Техники стабилизации

GAN известны нестабильностью обучения. Для решения нестабильности обучения были применены следующие техники:

### Image Pool
Дискриминатор, обучаясь только на самых свежих сгенерированных изображениях, может "забывать" предыдущие и начинать колебаться. Image Pool в данном проекте хранит историю из 50 последних сгенерированных изображений. При обучении дискриминатора с вероятностью 50% используется случайное изображение из пула вместо текущего. Это заставляет дискриминатор помнить о разных вариантах генерации и делает обучение более стабильным.

### Learning Rate Scheduling
В начале обучения нужен высокий learning rate для быстрого прогресса. По мере приближения к оптимуму, слишком большой шаг может привести к "проскакиванию" минимума. Постепенное снижение learning rate позволяет модели "устояться" и найти более качественное решение.

 ### Residual Connections
При прохождении через множество слоев возникает проблема затухающих градиентов. Поэтому было решено добавить residual блоки со skip connection (так называемый "обходной путь"). Таким образом, в генераторе используется 11 residual блоков, что позволяет создать глубокую сеть, способную на сложные преобразования стиля.

### InstanceNorm
BatchNorm нормализует по всему батчу изображений, а InstanceNorm нормализует каждое изображение отдельно. Стиль - это характеристика конкретного изображения, а не батча, поэтому в данном случае выбран InstanceNorm для сохранения особенностей каждого изображения.

## Гиперпараметры

```
Epoch: 55
Batch size: 6
Learning rate: 0.0002
Optimizer: Adam 
Lambda cycle: 10.0
Lambda identity: 0.5
Image pool size: 50
Residual blocks: 11
Save interval: 10
```

## Обучение

```python
# Инициализация модели
model = CycleGAN(device)

# Обучение
train_cyclegan(model, dataloader, num_epochs, save_interval)
```

**Время обучения (Kaggle GPU):** ~4.5 минуты на одну эпоху (всего 55 эпох) 


## Генерация изображений

**Быстрая визуализация результатов после обучения**

<img width="987" height="401" alt="image" src="https://github.com/user-attachments/assets/b16c9d99-ad5c-4e49-83e1-93f1242fe950" />


**Генерация всех изображений для submission**

```python
#Обработка батчами для оптимизации GPU памяти.
generated_count, zip_name = generate_monet_images(
    model=model,
    photo_dir=photo_dir,
    zip_name='images.zip',
    device=device,
    batch_size=8
)
```
**Визуализация результатов из случайно отобранных созданных изображений**

<img width="1007" height="655" alt="image" src="https://github.com/user-attachments/assets/c0145874-8247-44ad-96ba-111a4eed818d" />


## Результаты

Модель переносит характерные черты стиля Моне и сохраняет checkpoint каждые 10 эпох в формате `.pt`, включая:
- Веса генераторов
- Веса дискриминаторов
- Состояния оптимизаторов
- Номер эпохи

В соревновании Kaggle "I'm Something of a Painter Myself" данная реализация CycleGAN вошла в топ 15%  решений. 

## Дополнительные исследования

Так как в условиях участия в соревновании было указано, что время обучения модели и работа всего ноутбука должна ограничиваться 5 часами, модель была обучена всего на 55 эпохах (`cyclegan_monet_kaggle.ipynb`). В рамках эксперимента, вне соревнования, модель была также обучена на 155 эпохах с логгированием метрик в ClearML.(`cyclegan_monet_155_epoch_with_clearml.ipynb`)

**Графики потерь**

<img width="616" height="462" alt="image" src="https://github.com/user-attachments/assets/cb0bae3c-ba59-4bce-9b26-67418cb333ad" />

<img width="627" height="461" alt="image" src="https://github.com/user-attachments/assets/fd3badf4-8e69-4d0e-bb23-ca8d9a1e322f" />

<img width="616" height="462" alt="image" src="https://github.com/user-attachments/assets/859eb74b-329b-4f3a-85d1-72bb44e21210" />

**Визуализация результатов**

<img width="1015" height="409" alt="image" src="https://github.com/user-attachments/assets/496a53a7-1fb1-4694-a5fa-3efe9baa79a2" />

<img width="1020" height="407" alt="image" src="https://github.com/user-attachments/assets/daee1073-62ed-4c5e-aedc-d852bace03ab" />


Визуально модель, обученная на 155 эпохах, переносит характерные черты стиля Моне лучше, чем обученная на 55.



