{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install clearml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:49:02.878984Z",
     "iopub.status.busy": "2025-11-07T09:49:02.878257Z",
     "iopub.status.idle": "2025-11-07T09:49:14.884875Z",
     "shell.execute_reply": "2025-11-07T09:49:14.884283Z",
     "shell.execute_reply.started": "2025-11-07T09:49:02.878935Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Импорт необходимых библиотек для реализации CycleGAN\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "from clearml import Task, Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
    "%env CLEARML_API_HOST=https://api.clear.ml\n",
    "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
    "%env CLEARML_API_ACCESS_KEY=''\n",
    "%env CLEARML_API_SECRET_KEY=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:50:09.760509Z",
     "iopub.status.busy": "2025-11-07T09:50:09.759804Z",
     "iopub.status.idle": "2025-11-07T09:50:26.083048Z",
     "shell.execute_reply": "2025-11-07T09:50:26.081532Z",
     "shell.execute_reply.started": "2025-11-07T09:50:09.760482Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Инициализируем удаленную таску\n",
    "task = Task.init(\n",
    "        project_name=\"CycleGAN_Monet\",\n",
    "        task_name=\"CycleGAN_150_epoch\",\n",
    "        task_type=\"testing\",\n",
    ")\n",
    "task:Task\n",
    "\n",
    "logger = Logger.current_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:05.151186Z",
     "iopub.status.busy": "2025-11-07T09:51:05.149167Z",
     "iopub.status.idle": "2025-11-07T09:51:05.159329Z",
     "shell.execute_reply": "2025-11-07T09:51:05.158631Z",
     "shell.execute_reply.started": "2025-11-07T09:51:05.151148Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Фиксация seed для воспроизводимости результатов\n",
    "\n",
    "def fix_seeds(seed: int):\n",
    "    np.random.seed(seed)  # Для numpy операций\n",
    "    random.seed(seed)  # Для встроенного random, который используется в DataLoader\n",
    "    torch.manual_seed(seed)  # Для CPU операций PyTorch\n",
    "    torch.cuda.manual_seed(seed)  # Для GPU операций \n",
    "\n",
    "fix_seeds(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:07.938258Z",
     "iopub.status.busy": "2025-11-07T09:51:07.937706Z",
     "iopub.status.idle": "2025-11-07T09:51:07.943205Z",
     "shell.execute_reply": "2025-11-07T09:51:07.942388Z",
     "shell.execute_reply.started": "2025-11-07T09:51:07.938236Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создание Residual блок - ключевой компонент для глубоких сетей, который позволяет избежать проблемы затухающих градиентов через skip connection\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),  \n",
    "            nn.Conv2d(in_channels, in_channels, 3),\n",
    "            nn.InstanceNorm2d(in_channels), \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(in_channels, in_channels, 3),\n",
    "            nn.InstanceNorm2d(in_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.conv_block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:09.590468Z",
     "iopub.status.busy": "2025-11-07T09:51:09.590174Z",
     "iopub.status.idle": "2025-11-07T09:51:09.598313Z",
     "shell.execute_reply": "2025-11-07T09:51:09.597420Z",
     "shell.execute_reply.started": "2025-11-07T09:51:09.590446Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создание генератора с архитектурой encoder-transformer-decoder\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channels=3, output_channels=3, n_residual_blocks=11):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        # Encoder - начальный слой извлечения признаков\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_channels, 64, 7), \n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        \n",
    "        # Downsampling - уменьшение пространственного разрешения с увеличением каналов\n",
    "        in_channels = 64\n",
    "        for _ in range(2):\n",
    "            out_channels = in_channels * 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_channels, out_channels, 3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Transformer - обработка в пространстве признаков через residual блоки\n",
    "        for _ in range(n_residual_blocks):\n",
    "            model += [ResidualBlock(in_channels)]\n",
    "        \n",
    "        # Upsampling - восстановление исходного разрешения\n",
    "        for _ in range(2):\n",
    "            out_channels = in_channels // 2\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_channels, out_channels, 3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_channels = out_channels\n",
    "        \n",
    "        # Decoder - финальный слой для получения RGB изображения\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(64, output_channels, 7),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:12.166748Z",
     "iopub.status.busy": "2025-11-07T09:51:12.166459Z",
     "iopub.status.idle": "2025-11-07T09:51:12.173339Z",
     "shell.execute_reply": "2025-11-07T09:51:12.172516Z",
     "shell.execute_reply.started": "2025-11-07T09:51:12.166727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создание PatchGAN Discriminator - классифицирует не все изображение целиком, а отдельные патчи (небольшие области изображения).\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        # Вспомогательная функция для создания блоков дискриминатора\n",
    "        def discriminator_block(in_channels, out_channels, normalize=True):\n",
    "            layers = [nn.Conv2d(in_channels, out_channels, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_channels))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))  # LeakyReLU для стабильности обучения\n",
    "            return layers\n",
    "        \n",
    "        # Архитектура - серия сверточных слоев со stride=2 \n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(input_channels, 64, normalize=False),\n",
    "            *discriminator_block(64, 128),   \n",
    "            *discriminator_block(128, 256), \n",
    "            *discriminator_block(256, 512), \n",
    "            nn.ZeroPad2d((1, 0, 1, 0)),  # Асимметричный padding для корректной свертки\n",
    "            nn.Conv2d(512, 1, 4, padding=1)  # Карта вероятностей на выходе  \n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:14.619507Z",
     "iopub.status.busy": "2025-11-07T09:51:14.619210Z",
     "iopub.status.idle": "2025-11-07T09:51:14.626705Z",
     "shell.execute_reply": "2025-11-07T09:51:14.625829Z",
     "shell.execute_reply.started": "2025-11-07T09:51:14.619485Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создание Датасета\n",
    "\n",
    "class MonetPhotoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, monet_dir, photo_dir, transform=None):\n",
    "        self.monet_dir = monet_dir\n",
    "        self.photo_dir = photo_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Загрузка списков файлов\n",
    "        self.monet_files = [f for f in os.listdir(monet_dir) if f.endswith('.jpg')]\n",
    "        all_photo_files = [f for f in os.listdir(photo_dir) if f.endswith('.jpg')]\n",
    "        self.photo_files = random.sample(all_photo_files, k=1000) # Ограничиваем количество фото для ускорения обучения\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Определение длины бОльшим датасетом\n",
    "        return max(len(self.monet_files), len(self.photo_files))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Используется random.choice вместо индексации по idx, чтобы обеспечить случайное сопоставление\n",
    "        monet_file = random.choice(self.monet_files)\n",
    "        photo_file = random.choice(self.photo_files)\n",
    "        \n",
    "        monet_path = os.path.join(self.monet_dir, monet_file)\n",
    "        photo_path = os.path.join(self.photo_dir, photo_file)\n",
    "        \n",
    "        # Загрузка и конвертация в RGB\n",
    "        monet_img = Image.open(monet_path).convert('RGB')\n",
    "        photo_img = Image.open(photo_path).convert('RGB')\n",
    "        \n",
    "        # Подготовка изображений\n",
    "        if self.transform:\n",
    "            monet_img = self.transform(monet_img)\n",
    "            photo_img = self.transform(photo_img)\n",
    "            \n",
    "        return photo_img, monet_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:17.992668Z",
     "iopub.status.busy": "2025-11-07T09:51:17.992418Z",
     "iopub.status.idle": "2025-11-07T09:51:17.999282Z",
     "shell.execute_reply": "2025-11-07T09:51:17.998222Z",
     "shell.execute_reply.started": "2025-11-07T09:51:17.992652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создание Image Pool - для стабилизации обучения GAN\n",
    "\n",
    "class ImagePool:\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        # Возвращение изображения из истории вместо только текущих\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images:\n",
    "            image = torch.unsqueeze(image.data, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                # Заполнение pool до максимального размера\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                # Pool заполнен: с вероятностью 50% возвращается старое изображение\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    # Замена случайного изображения в pool и возвращение старого\n",
    "                    random_id = random.randint(0, self.pool_size - 1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    # Возвращение текущего изображения\n",
    "                    return_images.append(image)\n",
    "        return_images = torch.cat(return_images, 0)\n",
    "        return return_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:20.762368Z",
     "iopub.status.busy": "2025-11-07T09:51:20.762080Z",
     "iopub.status.idle": "2025-11-07T09:51:20.777225Z",
     "shell.execute_reply": "2025-11-07T09:51:20.776318Z",
     "shell.execute_reply.started": "2025-11-07T09:51:20.762349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Создание основного класса CycleGAN, объединяющего все компоненты\n",
    "\n",
    "class CycleGAN:\n",
    "    def __init__(self, device='cuda'):\n",
    "        self.device = device\n",
    "        \n",
    "        # Инициализация двух генераторов и двух дискриминаторов\n",
    "        self.G_photo_to_monet = Generator().to(device)\n",
    "        self.G_monet_to_photo = Generator().to(device)\n",
    "        self.D_photo = Discriminator().to(device)\n",
    "        self.D_monet = Discriminator().to(device)\n",
    "        \n",
    "        # Оптимизаторы Adam для генераторов и дискриминаторов\n",
    "        self.optimizer_G = optim.Adam(\n",
    "            list(self.G_photo_to_monet.parameters()) + list(self.G_monet_to_photo.parameters()),\n",
    "            lr=0.0002, betas=(0.5, 0.999)\n",
    "        )\n",
    "        self.optimizer_D_photo = optim.Adam(self.D_photo.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        self.optimizer_D_monet = optim.Adam(self.D_monet.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "        \n",
    "        # Schedulers для постепенного снижения learning rate для улучшения сходимости\n",
    "        self.scheduler_G = StepLR(self.optimizer_G, step_size=50, gamma=0.5)\n",
    "        self.scheduler_D_photo = StepLR(self.optimizer_D_photo, step_size=50, gamma=0.5)  \n",
    "        self.scheduler_D_monet = StepLR(self.optimizer_D_monet, step_size=50, gamma=0.5)\n",
    "\n",
    "        # Функции потерь для разных компонентов\n",
    "        self.criterion_gan = nn.MSELoss()  # Для adversarial loss (насколько хорошо генератор обманывает дискриминатор)\n",
    "        self.criterion_cycle = nn.L1Loss()  # Для cycle consistency loss (гарантия того, что преобразование обратимо)\n",
    "        self.criterion_identity = nn.L1Loss()  # Для identity loss (сохранение цветовой гаммы и предотвращение излишних изменений)\n",
    "        \n",
    "        # Веса для компонентов функции потерь\n",
    "        self.lambda_cycle = 10.0  # Cycle consistency - заставляет модель сохранять содержание изображения при преобразовании\n",
    "        self.lambda_identity = 0.5  # Identity loss - помогает сохранить цветовую гамму оригинала\n",
    "        \n",
    "        # Image pools для стабилизации обучения дискриминаторов - используют историю сгенерированных изображений вместо только текущих\n",
    "        self.fake_photo_buffer = ImagePool(50) # Хранит 50 последних сгенерированных изображений\n",
    "        self.fake_monet_buffer = ImagePool(50)\n",
    "    \n",
    "    def set_input(self, real_photo, real_monet):\n",
    "        # Перемещение батчей данных на устройство (CPU/GPU)\n",
    "        self.real_photo = real_photo.to(self.device)\n",
    "        self.real_monet = real_monet.to(self.device)\n",
    "    \n",
    "    def forward(self):\n",
    "        # Forward pass через оба генератора\n",
    "        self.fake_monet = self.G_photo_to_monet(self.real_photo) # photo - fake_monet - reconstructed_photo\n",
    "        self.rec_photo = self.G_monet_to_photo(self.fake_monet)\n",
    "        self.fake_photo = self.G_monet_to_photo(self.real_monet) # monet - fake_photo - reconstructed_monet\n",
    "        self.rec_monet = self.G_photo_to_monet(self.fake_photo)\n",
    "    \n",
    "    def backward_D_basic(self, netD, real, fake):\n",
    "        # Базовая функция для обучения дискриминатора (отличие реальных изображений от сгенерированных)\n",
    "        pred_real = netD(real)\n",
    "        loss_D_real = self.criterion_gan(pred_real, torch.ones_like(pred_real))\n",
    "        pred_fake = netD(fake.detach()) # Обязательное применение detach - останавливаем градиент через генератор\n",
    "        loss_D_fake = self.criterion_gan(pred_fake, torch.zeros_like(pred_fake))\n",
    "        \n",
    "        # Общий loss дискриминатора (среднее между real и fake)\n",
    "        loss_D = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D.backward()\n",
    "        return loss_D\n",
    "    \n",
    "    def backward_D_photo(self):\n",
    "        # Обучение дискриминатора для фото, используем image pool для стабилизации\n",
    "        fake_photo = self.fake_photo_buffer.query(self.fake_photo)\n",
    "        self.loss_D_photo = self.backward_D_basic(self.D_photo, self.real_photo, fake_photo)\n",
    "    \n",
    "    def backward_D_monet(self):\n",
    "        # Обучение дискриминатора для картин Моне\n",
    "        fake_monet = self.fake_monet_buffer.query(self.fake_monet)\n",
    "        self.loss_D_monet = self.backward_D_basic(self.D_monet, self.real_monet, fake_monet)\n",
    "        \n",
    "    def backward_G(self):\n",
    "        # Обучение генераторов\n",
    "        \n",
    "        # Identity Loss - сохранение цветовой схемы исходных изображений\n",
    "        idt_photo = self.G_monet_to_photo(self.real_photo)\n",
    "        loss_idt_photo = self.criterion_identity(idt_photo, self.real_photo) * self.lambda_cycle * self.lambda_identity\n",
    "        \n",
    "        idt_monet = self.G_photo_to_monet(self.real_monet)\n",
    "        loss_idt_monet = self.criterion_identity(idt_monet, self.real_monet) * self.lambda_cycle * self.lambda_identity\n",
    "        \n",
    "        # Adversarial Loss - обман дискриминаторов\n",
    "        pred_fake_photo = self.D_photo(self.fake_photo)\n",
    "        loss_G_monet_to_photo = self.criterion_gan(pred_fake_photo, torch.ones_like(pred_fake_photo))\n",
    "        pred_fake_monet = self.D_monet(self.fake_monet)\n",
    "        loss_G_photo_to_monet = self.criterion_gan(pred_fake_monet, torch.ones_like(pred_fake_monet))\n",
    "        \n",
    "        # Cycle Consistency Loss - гарантия того, что преобразование обратимо\n",
    "        loss_cycle_photo = self.criterion_cycle(self.rec_photo, self.real_photo) * self.lambda_cycle\n",
    "        loss_cycle_monet = self.criterion_cycle(self.rec_monet, self.real_monet) * self.lambda_cycle\n",
    "        \n",
    "        # Суммирование всех компонентов loss для генераторов\n",
    "        self.loss_G = loss_G_photo_to_monet + loss_G_monet_to_photo + loss_cycle_photo + loss_cycle_monet + loss_idt_photo + loss_idt_monet\n",
    "        self.loss_G.backward()\n",
    "    \n",
    "    def optimize_parameters(self):\n",
    "        # Полный цикл обучения для одного батча\n",
    "        \n",
    "        # Forward pass - генерируем все необходимые изображения\n",
    "        self.forward()\n",
    "\n",
    "        # Обновление генераторов\n",
    "        self.optimizer_G.zero_grad()  # Обнуляем градиенты\n",
    "        self.backward_G()  # Вычисляем градиенты\n",
    "        self.optimizer_G.step()  # Применяем обновление весов\n",
    "\n",
    "        # Обновление дискриминатора для фото\n",
    "        self.optimizer_D_photo.zero_grad()\n",
    "        self.backward_D_photo()\n",
    "        self.optimizer_D_photo.step()\n",
    "        \n",
    "        # Обновление дискриминатора для картин Моне\n",
    "        self.optimizer_D_monet.zero_grad()\n",
    "        self.backward_D_monet()\n",
    "        self.optimizer_D_monet.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:28.494094Z",
     "iopub.status.busy": "2025-11-07T09:51:28.493773Z",
     "iopub.status.idle": "2025-11-07T09:51:28.504123Z",
     "shell.execute_reply": "2025-11-07T09:51:28.503376Z",
     "shell.execute_reply.started": "2025-11-07T09:51:28.494069Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Основной цикл обучения CycleGAN\n",
    "\n",
    "def train_cyclegan(model, dataloader, num_epochs=200, save_interval=50):\n",
    "    # Перевод всех моделей в режим обучения\n",
    "    model.G_photo_to_monet.train()\n",
    "    model.G_monet_to_photo.train()\n",
    "    model.D_photo.train()\n",
    "    model.D_monet.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Начальные значения для вычисления средних значений loss\n",
    "        epoch_loss_G = 0\n",
    "        epoch_loss_D_photo = 0\n",
    "        epoch_loss_D_monet = 0\n",
    "        \n",
    "        progress_bar = tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')\n",
    "        \n",
    "        for i, (photos, monets) in enumerate(progress_bar):\n",
    "            # Установка входных данных и выполнение одного шага обучения\n",
    "            model.set_input(photos, monets)\n",
    "            model.optimize_parameters()\n",
    "            \n",
    "            # Накапливание losses для статистики\n",
    "            epoch_loss_G += model.loss_G.item()\n",
    "            epoch_loss_D_photo += model.loss_D_photo.item()\n",
    "            epoch_loss_D_monet += model.loss_D_monet.item()\n",
    "            \n",
    "            # # Отображение текущих losses в progress bar\n",
    "            # progress_bar.set_postfix({\n",
    "            #     'Loss_G': f'{model.loss_G.item():.4f}',\n",
    "            #     'Loss_D_Photo': f'{model.loss_D_photo.item():.4f}',\n",
    "            #     'Loss_D_Monet': f'{model.loss_D_monet.item():.4f}'\n",
    "            # })\n",
    "        \n",
    "        # Вычисление средних losses за эпоху\n",
    "        avg_loss_G = epoch_loss_G / len(dataloader)\n",
    "        avg_loss_D_photo = epoch_loss_D_photo / len(dataloader)\n",
    "        avg_loss_D_monet = epoch_loss_D_monet / len(dataloader)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{num_epochs} - '\n",
    "              f'Loss_G: {avg_loss_G:.4f}, '\n",
    "              f'Loss_D_Photo: {avg_loss_D_photo:.4f}, '\n",
    "              f'Loss_D_Monet: {avg_loss_D_monet:.4f}') \n",
    "        \n",
    "        # Логгирование метрик в ClearML\n",
    "        logger.report_scalar(title='Loss Generator', series='Loss_G', value=avg_loss_G, iteration=epoch)\n",
    "        logger.report_scalar(title='Loss Discriminator Photo', series='Loss_D_Photo', value=avg_loss_D_photo, iteration=epoch)\n",
    "        logger.report_scalar(title='Loss Discriminator Monet', series='Loss_D_Monet', value=avg_loss_D_monet, iteration=epoch)\n",
    "        \n",
    "        # Периодическое сохранение checkpoint для возможности продолжения обучения\n",
    "        if (epoch + 1) % save_interval == 0:\n",
    "            checkpoint_path = f'cyclegan_checkpoint_epoch_{epoch+1}.pt'\n",
    "            \n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'G_photo_to_monet': model.G_photo_to_monet.state_dict(),\n",
    "                'G_monet_to_photo': model.G_monet_to_photo.state_dict(),\n",
    "                'D_photo': model.D_photo.state_dict(),\n",
    "                'D_monet': model.D_monet.state_dict(),\n",
    "                'optimizer_G': model.optimizer_G.state_dict(),\n",
    "                'optimizer_D_photo': model.optimizer_D_photo.state_dict(),\n",
    "                'optimizer_D_monet': model.optimizer_D_monet.state_dict(),\n",
    "            }, checkpoint_path)\n",
    "            print(f'Модель сохранена на эпохе {epoch+1}')\n",
    "            \n",
    "            # Загружаем в ClearML с метаданными\n",
    "            task.upload_artifact(\n",
    "                name=f'checkpoint_epoch_{epoch+1}',\n",
    "                artifact_object=checkpoint_path,\n",
    "                metadata={\n",
    "                    'epoch': epoch+1,\n",
    "                    'avg_loss_G': float(avg_loss_G),\n",
    "                    'avg_loss_D_photo': float(avg_loss_D_photo),\n",
    "                    'avg_loss_D_monet': float(avg_loss_D_monet),\n",
    "                    'learning_rate': model.optimizer_G.param_groups[0]['lr']\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        # Обновление learning rate согласно scheduler\n",
    "        model.scheduler_G.step()\n",
    "        model.scheduler_D_photo.step()\n",
    "        model.scheduler_D_monet.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:51.328931Z",
     "iopub.status.busy": "2025-11-07T09:51:51.328387Z",
     "iopub.status.idle": "2025-11-07T09:51:51.341288Z",
     "shell.execute_reply": "2025-11-07T09:51:51.340513Z",
     "shell.execute_reply.started": "2025-11-07T09:51:51.328908Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Вспомогательная функция для денормализации и конвертации тензора в изображение\n",
    "def denorm_tensor_to_pil(img_tensor):\n",
    "    t = img_tensor.clone().cpu()\n",
    "    t = (t + 1.0) / 2.0  # Денормализация из [-1, 1] в [0, 1]\n",
    "    t = t.clamp(0,1)  # Обрезка значения для безопасности\n",
    "    t = (t * 255).byte()  # Конвертация в [0, 255]\n",
    "    t = t.permute(1,2,0).numpy()  # CHW в HWC  \n",
    "    return Image.fromarray(t) #Создание изображения из numpy массива\n",
    "\n",
    "# Функция для генерации всех изображений в стиле Моне и сохранения в zip (обработка батчами для эффективности на GPU)\n",
    "def generate_monet_images(model, photo_dir, zip_name='monet_generated.zip', device='cpu', batch_size=8):\n",
    "    # Модели в режиме train (т.к. InstanceNorm)\n",
    "    model.G_photo_to_monet.train()\n",
    "    model.G_monet_to_photo.train()\n",
    "    model.D_photo.train()\n",
    "    model.D_monet.train()\n",
    "    \n",
    "    # Подготовка данных для генерации\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,)*3, (0.5,)*3), \n",
    "    ])\n",
    "    \n",
    "    photo_files = [f for f in os.listdir(photo_dir) if f.lower().endswith(('.jpg','.jpeg','.png'))]\n",
    "    total_files = len(photo_files)\n",
    "    generated_count = 0\n",
    "    \n",
    "    print(f\"Начинаю генерацию {total_files} изображений батчами по {batch_size}...\")\n",
    "  \n",
    "    # Создание zip файла для submission\n",
    "    with zipfile.ZipFile(zip_name, 'w', zipfile.ZIP_DEFLATED, compresslevel=1) as zipf:\n",
    "        with torch.no_grad():  # Отключение вычисления градиентов\n",
    "            for batch_start in tqdm(range(0, total_files, batch_size), desc='Обработка батчей'):\n",
    "                batch_end = min(batch_start + batch_size, total_files)\n",
    "                batch_files = photo_files[batch_start:batch_end]\n",
    "                \n",
    "                # Формирование батча изображений\n",
    "                batch_images = []\n",
    "                valid_files = []\n",
    "                \n",
    "                for photo_file in batch_files:\n",
    "                    try:\n",
    "                        photo_path = os.path.join(photo_dir, photo_file)\n",
    "                        img = Image.open(photo_path).convert('RGB')\n",
    "                        img_tensor = transform(img)\n",
    "                        batch_images.append(img_tensor)\n",
    "                        valid_files.append(photo_file)\n",
    "                    except Exception as e:\n",
    "                        print(f'Ошибка загрузки {photo_file}: {e}')\n",
    "                        continue\n",
    "                \n",
    "                if not batch_images:\n",
    "                    continue\n",
    "                \n",
    "                # Объединение списка тензоров в один батч\n",
    "                batch_tensor = torch.stack(batch_images).to(device)\n",
    "                \n",
    "                # Генерация изображений в стиле Моне\n",
    "                if hasattr(model, 'G_photo_to_monet'):\n",
    "                    generated_batch = model.G_photo_to_monet(batch_tensor)\n",
    "                else:\n",
    "                    generated_batch = model(batch_tensor)\n",
    "                \n",
    "                # Сохранение каждого изображения из батча\n",
    "                for i, photo_file in enumerate(valid_files):\n",
    "                    try:\n",
    "                        out_tensor = generated_batch[i]\n",
    "                        # Денормализация из [-1, 1] в [0, 1]\n",
    "                        out_tensor = (out_tensor + 1.0) / 2.0\n",
    "                        out_tensor = out_tensor.clamp(0, 1)\n",
    "                        \n",
    "                        # Конвертация в PIL изображение\n",
    "                        out_tensor = (out_tensor * 255).byte()\n",
    "                        out_tensor = out_tensor.permute(1, 2, 0).cpu().numpy()\n",
    "                        pil_img = Image.fromarray(out_tensor)\n",
    "                        \n",
    "                        # Сохранение в памяти как JPEG\n",
    "                        img_bytes = io.BytesIO()\n",
    "                        pil_img.save(img_bytes, format='JPEG', quality=85, optimize=True)\n",
    "                        img_bytes.seek(0)\n",
    "                        \n",
    "                        # Добавление в zip архив с правильным именем для submission\n",
    "                        out_name = os.path.splitext(photo_file)[0] + '_monet.jpg'\n",
    "                        zipf.writestr(out_name, img_bytes.getvalue())\n",
    "                        generated_count += 1\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f'Ошибка обработки {photo_file}: {e}')\n",
    "                        continue\n",
    "                \n",
    "                # Очистка памяти для предотвращения OOM на GPU\n",
    "                del batch_tensor, generated_batch, batch_images\n",
    "                torch.cuda.empty_cache() if device == 'cuda' else None\n",
    "    \n",
    "    return generated_count, zip_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T09:51:57.049271Z",
     "iopub.status.busy": "2025-11-07T09:51:57.048687Z",
     "iopub.status.idle": "2025-11-07T09:51:57.697482Z",
     "shell.execute_reply": "2025-11-07T09:51:57.696810Z",
     "shell.execute_reply.started": "2025-11-07T09:51:57.049244Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Настройка устройства для обучения\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Используется устройство: {device}')\n",
    "\n",
    "# Пути к данным \n",
    "monet_dir = '/kaggle/input/gan-getting-started/monet_jpg'  \n",
    "photo_dir = '/kaggle/input/gan-getting-started/photo_jpg'  \n",
    "\n",
    "# Проверка наличия данных\n",
    "if not os.path.exists(monet_dir):\n",
    "    print(f'ОШИБКА: Каталог {monet_dir} не найден!')\n",
    "if not os.path.exists(photo_dir):\n",
    "    print(f'ОШИБКА: Каталог {photo_dir} не найден!')\n",
    "\n",
    "# Подготовка данных\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "if os.path.exists(monet_dir) and os.path.exists(photo_dir):\n",
    "    # Создание датасета и dataloader\n",
    "    dataset = MonetPhotoDataset(monet_dir, photo_dir, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=6, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    print(f'Датасет создан: {len(dataset)} пар изображений')\n",
    "    \n",
    "    # Инициализация модели CycleGAN\n",
    "    model = CycleGAN(device=device)\n",
    "    print('Модель CycleGAN создана')\n",
    "    \n",
    "    # Подсчет параметров для понимания размера модели\n",
    "    total_params = sum(p.numel() for p in model.G_photo_to_monet.parameters())\n",
    "    print(f'Количество параметров генератора: {total_params:,}')\n",
    "else:\n",
    "    print('Создание датасета пропущено из-за отсутствующих каталогов')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-07T06:05:36.640Z",
     "iopub.execute_input": "2025-11-06T18:09:04.846446Z",
     "iopub.status.busy": "2025-11-06T18:09:04.845592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Гиперпараметры обучения\n",
    "NUM_EPOCHS = 201  \n",
    "SAVE_INTERVAL = 50  \n",
    "\n",
    "# Запуск процесса обучения\n",
    "train_cyclegan(model, dataloader, num_epochs=NUM_EPOCHS, save_interval=SAVE_INTERVAL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T10:08:02.410714Z",
     "iopub.status.busy": "2025-11-07T10:08:02.410406Z",
     "iopub.status.idle": "2025-11-07T10:08:13.610061Z",
     "shell.execute_reply": "2025-11-07T10:08:13.609365Z",
     "shell.execute_reply.started": "2025-11-07T10:08:02.410692Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ID задачи, где хранится артефакт\n",
    "task_id = 'bae9d2d4c61349b7b8ce92ae8000ae7b'\n",
    "\n",
    "# Создаём пустой объект CycleGAN (такой же, как при обучении)\n",
    "model = CycleGAN(device=device)\n",
    "\n",
    "# Загружаем задачу\n",
    "task = Task.get_task(task_id=task_id)\n",
    "\n",
    "# Смотрим, какие артефакты есть у задачи\n",
    "print('Доступные артефакты:', list(task.artifacts.keys()))\n",
    "\n",
    "# Берём нужный артефакт (например, checkpoint)\n",
    "artifact = task.artifacts['checkpoint_epoch_150']  # подставьте правильное имя \n",
    "\n",
    "# Скачиваем файл локально\n",
    "local_path = artifact.get_local_copy()\n",
    "print('Веса скачаны в:', local_path)\n",
    "\n",
    "# Загружаем веса в модель\n",
    "checkpoint = torch.load(local_path, map_location=device)\n",
    "model.G_photo_to_monet.load_state_dict(checkpoint['G_photo_to_monet'])\n",
    "model.G_monet_to_photo.load_state_dict(checkpoint['G_monet_to_photo'])\n",
    "model.D_photo.load_state_dict(checkpoint['D_photo'])\n",
    "model.D_monet.load_state_dict(checkpoint['D_monet'])\n",
    "\n",
    "print('Веса успешно восстановлены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-07T10:10:39.227628Z",
     "iopub.status.busy": "2025-11-07T10:10:39.227333Z",
     "iopub.status.idle": "2025-11-07T10:10:42.539786Z",
     "shell.execute_reply": "2025-11-07T10:10:42.538686Z",
     "shell.execute_reply.started": "2025-11-07T10:10:39.227604Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Функция для быстрой визуализации результатов после обучения\n",
    "\n",
    "def quick_generate_samples(model, photo_dir, num_samples=5):\n",
    "    model.G_photo_to_monet.train()\n",
    "    model.G_monet_to_photo.train()\n",
    "    model.D_photo.train()\n",
    "    model.D_monet.train()\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # Выбор случайных фотографий для демонстрации\n",
    "    photo_files = [f for f in os.listdir(photo_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    selected_photos = random.sample(photo_files, min(num_samples, len(photo_files)))\n",
    "    \n",
    "    print(\"Быстрая генерация примеров\")\n",
    "    \n",
    "    # Визуализация примеров\n",
    "    fig, axes = plt.subplots(2, num_samples, figsize=(20, 8))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(2, 1)\n",
    "    \n",
    "    with torch.no_grad():  \n",
    "        for i, photo_file in tqdm(enumerate(selected_photos)):\n",
    "            try:\n",
    "                photo_path = os.path.join(photo_dir, photo_file)\n",
    "                original_img = Image.open(photo_path).convert('RGB')\n",
    "                \n",
    "                # Преобравание в тензор и генерирование стилизованного изображения\n",
    "                input_tensor = transform(original_img).unsqueeze(0).to(device)\n",
    "                generated_monet = model.G_photo_to_monet(input_tensor)\n",
    "                # Денормализация для отображения\n",
    "                generated_monet = (generated_monet * 0.5 + 0.5).clamp(0, 1)\n",
    "                generated_img = transforms.ToPILImage()(generated_monet.squeeze(0).cpu())\n",
    "                \n",
    "                # Отображение оригинала и результата\n",
    "                axes[0, i].imshow(original_img)\n",
    "                axes[0, i].set_title('Оригинал')\n",
    "                axes[0, i].axis('off')\n",
    "                \n",
    "                axes[1, i].imshow(generated_img)\n",
    "                axes[1, i].set_title('Стиль Моне')\n",
    "                axes[1, i].axis('off')\n",
    "                \n",
    "                print(f\"Обработано: {photo_file}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка: {photo_file} - {e}\")\n",
    "                axes[0, i].axis('off')\n",
    "                axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Визуализация результатов на num_samples случайных примерах\n",
    "if os.path.exists(photo_dir):\n",
    "    quick_generate_samples(model, photo_dir, num_samples=5)\n",
    "else:\n",
    "    print(\"Каталог с фото не найден!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-07T06:05:36.665Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Генерация всех изображений для submission в Kaggle\n",
    "\n",
    "generated_count, zip_name = generate_monet_images(\n",
    "    model=model,\n",
    "    photo_dir=photo_dir,\n",
    "    zip_name='images.zip',  \n",
    "    device=device,\n",
    "    batch_size=8  \n",
    ")\n",
    "\n",
    "print(f\"Сгенерировано {generated_count} изображений в файле {zip_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-07T06:05:36.666Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Расширенная функция для визуализации - сравнение оригинального фото, генерации и реальной картины Моне\n",
    "\n",
    "def visualize_results(model, photo_dir, monet_dir, num_samples=4):\n",
    "    model.G_photo_to_monet.train()\n",
    "    model.G_monet_to_photo.train()\n",
    "    model.D_photo.train()\n",
    "    model.D_monet.train()\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    \n",
    "    # Выбор случайных изображений\n",
    "    photo_files = [f for f in os.listdir(photo_dir) if f.endswith('.jpg')]\n",
    "    monet_files = [f for f in os.listdir(monet_dir) if f.endswith('.jpg')]\n",
    "    \n",
    "    selected_photos = random.sample(photo_files, min(num_samples, len(photo_files)))\n",
    "    selected_monets = random.sample(monet_files, min(num_samples, len(monet_files)))\n",
    "    \n",
    "    # Создание сетки\n",
    "    fig, axes = plt.subplots(3, num_samples, figsize=(15, 9))\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(3, 1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_samples):\n",
    "            # Загрузка и преобразование фотографии\n",
    "            photo_path = os.path.join(photo_dir, selected_photos[i])\n",
    "            photo_img = Image.open(photo_path).convert('RGB')\n",
    "            photo_tensor = transform(photo_img).unsqueeze(0).to(model.device)\n",
    "            \n",
    "            # Генерирование изображения в стиле Моне\n",
    "            fake_monet = model.G_photo_to_monet(photo_tensor)\n",
    "            fake_monet = (fake_monet * 0.5 + 0.5).clamp(0, 1)  # Денормализация\n",
    "            fake_monet_img = transforms.ToPILImage()(fake_monet.squeeze(0).cpu())\n",
    "            \n",
    "            # Загрузка реальной картины Моне для сравнения\n",
    "            monet_path = os.path.join(monet_dir, selected_monets[i])\n",
    "            monet_img = Image.open(monet_path).convert('RGB')\n",
    "            \n",
    "            # Отображение всех трех изображений в колонке\n",
    "            axes[0, i].imshow(photo_img)\n",
    "            axes[0, i].set_title('Оригинальная фотография')\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            axes[1, i].imshow(fake_monet_img)\n",
    "            axes[1, i].set_title('Сгенерированная картина')\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            axes[2, i].imshow(monet_img)\n",
    "            axes[2, i].set_title('Оригинальная картина Моне')\n",
    "            axes[2, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-07T06:05:36.668Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Финальная визуализация для сравнения результатов модели с реальными картинами Моне\n",
    "\n",
    "if os.path.exists(monet_dir) and os.path.exists(photo_dir):\n",
    "    print('Примеры результатов.')\n",
    "    visualize_results(model, photo_dir, monet_dir, num_samples=4)\n",
    "else:\n",
    "    print('Каталоги с данными не найдены. Проверьте пути к monet_dir и photo_dir.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-11-07T06:05:36.670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "task.close()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 1475600,
     "sourceId": 21755,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
